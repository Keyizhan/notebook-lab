{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "899e2e38",
   "metadata": {},
   "source": [
    "# GCPNet 结合位点三图特征提取流水线（使用完整版 gcpnet）\n",
    "\n",
    "目标：\n",
    "- 从 PDB 复合物结构 + `binding_sites.csv` 中的关键残基信息出发；\n",
    "- 为每个 (PDB, 配体) 样本构建三张图：\n",
    "  - 蛋白 binding 残基图（Cα 节点）；\n",
    "  - 配体原子图；\n",
    "  - 蛋白–配体相互作用图；\n",
    "- 使用你新导入的完整版 `gcpnet` 及其 YAML 配置 (`config_gcpnet_encoder.yaml`) 初始化原版 `GCPNetModel`；\n",
    "- 对三张图分别编码并拼接，最终导出 `binding_embeddings_triplet.csv`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd3bc4ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ 成功导入 gcpnet 模块\n"
     ]
    }
   ],
   "source": [
    "# 基础依赖 & GCPNet 特征模块\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import math\n",
    "import csv\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# PDB 解析\n",
    "from Bio.PDB import PDBParser\n",
    "\n",
    "# 数学/图构建\n",
    "import torch\n",
    "from torch_geometric.data import Data, Batch\n",
    "\n",
    "# 添加 gcpnet 父目录到 Python 路径\n",
    "BASE_DIR = Path(r\"c:\\Users\\Administrator\\Desktop\\IGEM\\stage1\\notebook-lab\")\n",
    "if str(BASE_DIR) not in sys.path:\n",
    "    sys.path.insert(0, str(BASE_DIR))\n",
    "\n",
    "# gcpnet 特征模块\n",
    "from gcpnet.features.factory import ProteinFeaturiser\n",
    "from gcpnet.models.graph_encoders.gcpnet import GCPNetModel\n",
    "\n",
    "print(f\"✓ 成功导入 gcpnet 模块\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d4a0b7",
   "metadata": {},
   "source": [
    "## Part 1：蛋白口袋图构建与 GCPNet 特征（已实现部分的小结）\n",
    "\n",
    "这一部分沿用前面已经实现的逻辑：\n",
    "- 从 PDB 构建蛋白 Cα 图（节点=残基，边=KNN）；\n",
    "- 根据 binding_sites 标记 binding 残基；\n",
    "- 使用 ProteinFeaturiser 提取氨基酸 one-hot 与几何边特征；\n",
    "\n",
    "在后续的高级版本中，我们会在此基础上再接入 GCPNet encoder，对节点进行多层消息传播，然后对节点 embedding 做 pooling 得到蛋白侧的口袋 embedding。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c25976d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import csv\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7cd0c8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n",
    "import math\n",
    "import csv\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6319ea9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 路径与全局参数\n",
    "BASE_DIR = Path(r\"c:\\Users\\Administrator\\Desktop\\IGEM\\stage1\\notebook-lab\")\n",
    "\n",
    "PDB_DIR = BASE_DIR / \"complex-20251129T063258Z-1-001\" / \"complex\"\n",
    "BINDING_CSV = BASE_DIR / \"binding_sites.csv\"\n",
    "\n",
    "# 输出的结合嵌入结果\n",
    "BINDING_EMBEDDINGS_CSV = BASE_DIR / \"binding_embeddings.csv\"\n",
    "\n",
    "# 图构建参数\n",
    "K_NEIGHBORS = 16    # KNN 图的 K\n",
    "\n",
    "# 简单氨基酸 3 字母到整数编码\n",
    "AA3_TO_ID = {\n",
    "    \"ALA\": 0, \"CYS\": 1, \"ASP\": 2, \"GLU\": 3, \"PHE\": 4,\n",
    "    \"GLY\": 5, \"HIS\": 6, \"ILE\": 7, \"LYS\": 8, \"LEU\": 9,\n",
    "    \"MET\": 10, \"ASN\": 11, \"PRO\": 12, \"GLN\": 13, \"ARG\": 14,\n",
    "    \"SER\": 15, \"THR\": 16, \"VAL\": 17, \"TRP\": 18, \"TYR\": 19,\n",
    "}\n",
    "UNKNOWN_AA_ID = len(AA3_TO_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41673234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "共 25626 条 binding 记录，3139 个 (pdb, ligand) 组合。\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('0', 'FAD', 'B', 1),\n",
       " ('1', 'UNL', ' ', 1),\n",
       " ('100', 'UNL', ' ', 1),\n",
       " ('1000', 'UNL', ' ', 1),\n",
       " ('1001', 'UNL', ' ', 1)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 读取 binding_sites.csv，并按 (pdb_id, ligand) 分组\n",
    "\n",
    "def load_binding_sites(csv_path: Path):\n",
    "    \"\"\"按 (pdb_id, ligand_resname, ligand_chain, ligand_resnum) 分组 binding 记录。\"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    groups = defaultdict(list)\n",
    "    for _, row in df.iterrows():\n",
    "        key = (\n",
    "            str(row[\"pdb_id\"]),\n",
    "            str(row[\"ligand_resname\"]),\n",
    "            str(row[\"ligand_chain\"]),\n",
    "            int(row[\"ligand_resnum\"]),\n",
    "        )\n",
    "        groups[key].append(row)\n",
    "\n",
    "    print(f\"共 {len(df)} 条 binding 记录，{len(groups)} 个 (pdb, ligand) 组合。\")\n",
    "    return groups\n",
    "\n",
    "binding_groups = load_binding_sites(BINDING_CSV)\n",
    "list(binding_groups.keys())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ee179e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从 PDB 构建 Cα 图\n",
    "\n",
    "parser = PDBParser(QUIET=True)\n",
    "\n",
    "\n",
    "def build_ca_graph_from_pdb(pdb_path: Path, protein_chains=None):\n",
    "    \"\"\"从 PDB 构建一个 Cα 图：返回链 ID、残基号、Cα 坐标、氨基酸类型 ID、KNN 边。\"\"\"\n",
    "    structure = parser.get_structure(pdb_path.stem, str(pdb_path))\n",
    "    model = next(structure.get_models())  # 取第一个 model\n",
    "\n",
    "    ca_coords = []\n",
    "    chain_ids = []\n",
    "    resnums = []\n",
    "    res_types = []\n",
    "\n",
    "    for chain in model:\n",
    "        chain_id = chain.id\n",
    "        if protein_chains and chain_id not in protein_chains:\n",
    "            continue\n",
    "\n",
    "        for residue in chain:\n",
    "            hetfield = residue.id[0]\n",
    "            if hetfield.strip():  # 排除 HETATM\n",
    "                continue\n",
    "\n",
    "            resname = residue.get_resname().strip()\n",
    "            if \"CA\" not in residue:\n",
    "                continue\n",
    "            ca = residue[\"CA\"]\n",
    "\n",
    "            ca_coords.append(ca.coord)\n",
    "            chain_ids.append(chain_id)\n",
    "            resnums.append(residue.id[1])\n",
    "            res_types.append(AA3_TO_ID.get(resname, UNKNOWN_AA_ID))\n",
    "\n",
    "    if not ca_coords:\n",
    "        return [], [], None, None, None\n",
    "\n",
    "    coords = torch.tensor(ca_coords, dtype=torch.float32)  # [N,3]\n",
    "    residue_type_ids = torch.tensor(res_types, dtype=torch.long)  # [N]\n",
    "\n",
    "    # KNN 图\n",
    "    N = coords.shape[0]\n",
    "    if N == 1:\n",
    "        edge_index = torch.zeros((2, 0), dtype=torch.long)\n",
    "    else:\n",
    "        dist_mat = torch.cdist(coords, coords)\n",
    "        knn = min(K_NEIGHBORS, N - 1)\n",
    "        _, knn_idx = torch.topk(-dist_mat, k=knn + 1, dim=-1)  # +1 包含自己\n",
    "\n",
    "        rows, cols = [], []\n",
    "        for i in range(N):\n",
    "            for j in knn_idx[i].tolist():\n",
    "                if i == j:\n",
    "                    continue\n",
    "                rows.append(i)\n",
    "                cols.append(j)\n",
    "        edge_index = torch.tensor([rows, cols], dtype=torch.long)\n",
    "\n",
    "    return chain_ids, resnums, coords, residue_type_ids, edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "791aea74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据 binding_sites 标注图，并构建 PyG Data\n",
    "\n",
    "\n",
    "def build_pyg_data_for_group(pdb_dir: Path, group_key, group_rows, protein_chains=None):\n",
    "    \"\"\"对一个 (pdb, ligand) group：构建 Cα 图并在节点上打 binding 标签。\"\"\"\n",
    "    pdb_id, lig_resname, lig_chain, lig_resnum = group_key\n",
    "    pdb_path = pdb_dir / f\"{pdb_id}.pdb\"\n",
    "    if not pdb_path.exists():\n",
    "        print(f\"PDB 文件不存在：{pdb_path}\")\n",
    "        return None\n",
    "\n",
    "    node_chain_ids, node_resnums, coords, res_type_ids, edge_index = build_ca_graph_from_pdb(\n",
    "        pdb_path, protein_chains=protein_chains\n",
    "    )\n",
    "    if coords is None:\n",
    "        print(f\"在 {pdb_path} 中未找到蛋白 Cα 节点。\")\n",
    "        return None\n",
    "\n",
    "    N = coords.shape[0]\n",
    "\n",
    "    # (chain, resnum) -> node_idx\n",
    "    index_map = {\n",
    "        (cid, int(rnum)): i\n",
    "        for i, (cid, rnum) in enumerate(zip(node_chain_ids, node_resnums))\n",
    "    }\n",
    "\n",
    "    # 生成 binding 标签\n",
    "    y = torch.zeros(N, dtype=torch.long)\n",
    "    for row in group_rows:\n",
    "        cid = str(row[\"protein_chain\"])\n",
    "        rnum = int(row[\"protein_resnum\"])\n",
    "        idx = index_map.get((cid, rnum))\n",
    "        if idx is not None:\n",
    "            y[idx] = 1\n",
    "\n",
    "    data = Data()\n",
    "    data.pos = coords               # [N,3]\n",
    "    data.residue_type = res_type_ids  # [N]\n",
    "    data.edge_index = edge_index    # [2,E]\n",
    "    data.y = y                      # [N]\n",
    "\n",
    "    data.pdb_id = pdb_id\n",
    "    data.ligand_resname = lig_resname\n",
    "    data.ligand_chain = lig_chain\n",
    "    data.ligand_resnum = int(lig_resnum)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5bbcb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将多个 Data 合并为 Batch，并构造 coords/seq_pos 供 ProteinFeaturiser 使用\n",
    "\n",
    "\n",
    "def to_batch_for_featuriser(data_list):\n",
    "    \"\"\"合并为 Batch，并填充 coords / seq_pos 字段。\"\"\"\n",
    "    batch = Batch.from_data_list(data_list)\n",
    "\n",
    "    pos = batch.pos  # [N,3]\n",
    "    zeros = torch.zeros_like(pos)\n",
    "    coords = torch.stack([zeros, pos], dim=1)  # [N,2,3]，index 1 作为 Cα\n",
    "\n",
    "    batch.coords = coords\n",
    "    batch.seq_pos = torch.arange(pos.size(0), dtype=torch.long)\n",
    "\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3402f2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# “完整版” featuriser 配置：节点 one-hot + 边距离/方向\n",
    "\n",
    "featuriser = ProteinFeaturiser(\n",
    "    representation=\"CA\",  # 使用 coords[:,1,:] 作为 Cα\n",
    "    scalar_node_features=[\n",
    "        \"amino_acid_one_hot\",\n",
    "        # 如需序列位置编码，可解开下一行\n",
    "        # \"sequence_positional_encoding\",\n",
    "    ],\n",
    "    vector_node_features=[],\n",
    "    edge_types=[\"knn_16\"],\n",
    "    scalar_edge_features=[\"edge_distance\"],\n",
    "    vector_edge_features=[\"edge_vectors\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2a21838",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_721200\\3129801301.py:39: UserWarning:\n",
      "\n",
      "Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:256.)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已保存 50 条样本到 c:\\Users\\Administrator\\Desktop\\IGEM\\stage1\\notebook-lab\\binding_embeddings.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pdb_id</th>\n",
       "      <th>ligand_resname</th>\n",
       "      <th>ligand_chain</th>\n",
       "      <th>ligand_resnum</th>\n",
       "      <th>feat_0</th>\n",
       "      <th>feat_1</th>\n",
       "      <th>feat_2</th>\n",
       "      <th>feat_3</th>\n",
       "      <th>feat_4</th>\n",
       "      <th>feat_5</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_13</th>\n",
       "      <th>feat_14</th>\n",
       "      <th>feat_15</th>\n",
       "      <th>feat_16</th>\n",
       "      <th>feat_17</th>\n",
       "      <th>feat_18</th>\n",
       "      <th>feat_19</th>\n",
       "      <th>feat_20</th>\n",
       "      <th>feat_21</th>\n",
       "      <th>feat_22</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>FAD</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>0.184211</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.131579</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078947</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>0.078947</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>UNL</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>UNL</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000</td>\n",
       "      <td>UNL</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1001</td>\n",
       "      <td>UNL</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  pdb_id ligand_resname ligand_chain  ligand_resnum    feat_0    feat_1  \\\n",
       "0      0            FAD            B              1  0.184211  0.026316   \n",
       "1      1            UNL                           1  0.000000  0.000000   \n",
       "2    100            UNL                           1  0.400000  0.000000   \n",
       "3   1000            UNL                           1  0.000000  0.000000   \n",
       "4   1001            UNL                           1  0.000000  0.000000   \n",
       "\n",
       "     feat_2    feat_3    feat_4    feat_5  ...   feat_13   feat_14   feat_15  \\\n",
       "0  0.052632  0.026316  0.052632  0.131579  ...  0.026316  0.000000  0.078947   \n",
       "1  0.000000  0.000000  0.000000  0.000000  ...  0.200000  0.000000  0.000000   \n",
       "2  0.000000  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.100000   \n",
       "3  0.000000  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.200000   \n",
       "4  0.000000  0.000000  0.000000  0.000000  ...  0.000000  0.166667  0.000000   \n",
       "\n",
       "    feat_16   feat_17  feat_18   feat_19  feat_20  feat_21  feat_22  \n",
       "0  0.026316  0.078947      0.0  0.026316      0.0      0.0      0.0  \n",
       "1  0.000000  0.000000      0.0  0.200000      0.0      0.0      0.0  \n",
       "2  0.000000  0.000000      0.0  0.100000      0.0      0.0      0.0  \n",
       "3  0.200000  0.000000      0.0  0.200000      0.0      0.0      0.0  \n",
       "4  0.166667  0.000000      0.0  0.000000      0.0      0.0      0.0  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 计算每个 (pdb, ligand) 的 binding embedding 并导出\n",
    "\n",
    "\n",
    "def compute_binding_embeddings(\n",
    "    pdb_dir: Path,\n",
    "    binding_groups: dict,\n",
    "    max_groups: int | None = 50,\n",
    "    protein_chains=None,\n",
    "):\n",
    "    keys = list(binding_groups.keys())\n",
    "    if max_groups is not None:\n",
    "        keys = keys[:max_groups]\n",
    "\n",
    "    data_list = []\n",
    "    meta_list = []\n",
    "\n",
    "    for key in keys:\n",
    "        group_rows = binding_groups[key]\n",
    "        data = build_pyg_data_for_group(pdb_dir, key, group_rows, protein_chains)\n",
    "        if data is None:\n",
    "            continue\n",
    "        data_list.append(data)\n",
    "        meta_list.append(key)\n",
    "\n",
    "    if not data_list:\n",
    "        print(\"没有成功构建的样本。\")\n",
    "        return None\n",
    "\n",
    "    batch = to_batch_for_featuriser(data_list)\n",
    "    batch = featuriser(batch)\n",
    "\n",
    "    x = batch.x       # [总节点数, F]\n",
    "    y = batch.y       # [总节点数]\n",
    "    graph_idx = batch.batch  # [总节点数]\n",
    "\n",
    "    h_list = []\n",
    "    meta_records = []\n",
    "\n",
    "    num_graphs = int(graph_idx.max().item()) + 1\n",
    "    for g in range(num_graphs):\n",
    "        mask_g = (graph_idx == g)\n",
    "        x_g = x[mask_g]\n",
    "        y_g = y[mask_g]\n",
    "\n",
    "        mask_binding = (y_g > 0)\n",
    "        if mask_binding.any():\n",
    "            h_binding = x_g[mask_binding].mean(dim=0)\n",
    "        else:\n",
    "            h_binding = x_g.mean(dim=0)\n",
    "\n",
    "        pdb_id, lig_resname, lig_chain, lig_resnum = meta_list[g]\n",
    "        meta_records.append({\n",
    "            \"pdb_id\": pdb_id,\n",
    "            \"ligand_resname\": lig_resname,\n",
    "            \"ligand_chain\": lig_chain,\n",
    "            \"ligand_resnum\": lig_resnum,\n",
    "        })\n",
    "        h_list.append(h_binding.detach().cpu().numpy())\n",
    "\n",
    "    if not h_list:\n",
    "        print(\"未得到任何 embedding。\")\n",
    "        return None\n",
    "\n",
    "    H = np.stack(h_list, axis=0)\n",
    "    df_meta = pd.DataFrame(meta_records)\n",
    "    df_emb = pd.DataFrame(H, columns=[f\"feat_{i}\" for i in range(H.shape[1])])\n",
    "    df_out = pd.concat([df_meta, df_emb], axis=1)\n",
    "\n",
    "    df_out.to_csv(BINDING_EMBEDDINGS_CSV, index=False)\n",
    "    print(f\"已保存 {len(df_out)} 条样本到 {BINDING_EMBEDDINGS_CSV}\")\n",
    "\n",
    "    return df_out\n",
    "\n",
    "\n",
    "# 实际运行（先只跑前 50 组）\n",
    "df_binding_emb = compute_binding_embeddings(PDB_DIR, binding_groups, max_groups=50)\n",
    "df_binding_emb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a76a762c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基础依赖\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n",
    "import math\n",
    "import csv\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# PDB 解析\n",
    "from Bio.PDB import PDBParser\n",
    "\n",
    "# 数学/图构建\n",
    "import torch\n",
    "from torch_geometric.data import Data, Batch\n",
    "\n",
    "# gcpnet 特征模块\n",
    "from gcpnet.features.factory import ProteinFeaturiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7dcee57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = Path(r\"c:\\Users\\Administrator\\Desktop\\IGEM\\stage1\\notebook-lab\")\n",
    "\n",
    "PDB_DIR = BASE_DIR / \"complex-20251129T063258Z-1-001\" / \"complex\"\n",
    "BINDING_CSV = BASE_DIR / \"binding_sites.csv\"\n",
    "\n",
    "# 输出的 “结合嵌入” 文件\n",
    "BINDING_EMBEDDINGS_CSV = BASE_DIR / \"binding_embeddings.csv\"\n",
    "\n",
    "# 图构建参数\n",
    "K_NEIGHBORS = 16    # KNN 图的 K\n",
    "DIST_CUTOFF = 4.0   # （已有 binding_sites 已经用过，此处构图主要看邻近关系）\n",
    "\n",
    "# 简单的氨基酸 3 字母到整数编码（不全，但够常见）\n",
    "AA3_TO_ID = {\n",
    "    \"ALA\": 0, \"CYS\": 1, \"ASP\": 2, \"GLU\": 3, \"PHE\": 4,\n",
    "    \"GLY\": 5, \"HIS\": 6, \"ILE\": 7, \"LYS\": 8, \"LEU\": 9,\n",
    "    \"MET\": 10, \"ASN\": 11, \"PRO\": 12, \"GLN\": 13, \"ARG\": 14,\n",
    "    \"SER\": 15, \"THR\": 16, \"VAL\": 17, \"TRP\": 18, \"TYR\": 19,\n",
    "}\n",
    "\n",
    "UNKNOWN_AA_ID = len(AA3_TO_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9453f1ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "共 25626 条 binding 记录，分成 3139 个 (pdb, ligand) 组。\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('0', 'FAD', 'B', 1),\n",
       " ('1', 'UNL', ' ', 1),\n",
       " ('100', 'UNL', ' ', 1),\n",
       " ('1000', 'UNL', ' ', 1),\n",
       " ('1001', 'UNL', ' ', 1)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_binding_sites(csv_path: Path):\n",
    "    \"\"\"\n",
    "    将 binding_sites.csv 按 (pdb_id, ligand_resname, ligand_chain, ligand_resnum) 分组。\n",
    "\n",
    "    返回：\n",
    "    - groups: dict[key -> list[rows]]\n",
    "      key = (pdb_id, lig_resname, lig_chain, lig_resnum)\n",
    "      每个元素 row 为 dict，包含蛋白残基的链 / 号等。\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    groups = defaultdict(list)\n",
    "    for _, row in df.iterrows():\n",
    "        key = (\n",
    "            str(row[\"pdb_id\"]),\n",
    "            str(row[\"ligand_resname\"]),\n",
    "            str(row[\"ligand_chain\"]),\n",
    "            int(row[\"ligand_resnum\"]),\n",
    "        )\n",
    "        groups[key].append(row)\n",
    "\n",
    "    print(f\"共 {len(df)} 条 binding 记录，\"\n",
    "          f\"分成 {len(groups)} 个 (pdb, ligand) 组。\")\n",
    "    return groups\n",
    "\n",
    "binding_groups = load_binding_sites(BINDING_CSV)\n",
    "list(binding_groups.keys())[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63cdfb8f",
   "metadata": {},
   "source": [
    "从 PDB 构建 Cα 图（Code）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb64d171",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = PDBParser(QUIET=True)\n",
    "\n",
    "def build_ca_graph_from_pdb(pdb_path: Path, protein_chains=None):\n",
    "    \"\"\"\n",
    "    从 PDB 构建一个 Cα 图：\n",
    "    - 节点：指定链上的每个残基（Cα）\n",
    "    - 特征：暂时只保留 residue_type（以后由 ProteinFeaturiser 补全）\n",
    "    - 坐标：Cα 的 3D 坐标\n",
    "    - 边：KNN 邻接（在坐标空间下）\n",
    "\n",
    "    返回：\n",
    "    - node_chain_ids: list of chain id\n",
    "    - node_resnums:  list of residue number\n",
    "    - coords: FloatTensor [N, 3]\n",
    "    - residue_type_ids: LongTensor [N]\n",
    "    - edge_index: LongTensor [2, E]\n",
    "    \"\"\"\n",
    "    structure = parser.get_structure(pdb_path.stem, str(pdb_path))\n",
    "    model = next(structure.get_models())  # 取第一个 model\n",
    "\n",
    "    ca_coords = []\n",
    "    chain_ids = []\n",
    "    resnums = []\n",
    "    res_types = []\n",
    "\n",
    "    for chain in model:\n",
    "        chain_id = chain.id\n",
    "        if protein_chains and chain_id not in protein_chains:\n",
    "            continue\n",
    "\n",
    "        for residue in chain:\n",
    "            hetfield = residue.id[0]\n",
    "            if hetfield.strip():  # 排除 HETATM\n",
    "                continue\n",
    "\n",
    "            resname = residue.get_resname().strip()\n",
    "            # 找到 Cα 原子\n",
    "            if \"CA\" not in residue:\n",
    "                continue\n",
    "            ca = residue[\"CA\"]\n",
    "\n",
    "            ca_coords.append(ca.coord)\n",
    "            chain_ids.append(chain_id)\n",
    "            resnums.append(residue.id[1])\n",
    "\n",
    "            res_types.append(AA3_TO_ID.get(resname, UNKNOWN_AA_ID))\n",
    "\n",
    "    if not ca_coords:\n",
    "        return [], [], None, None, None\n",
    "\n",
    "    coords = torch.tensor(ca_coords, dtype=torch.float32)  # [N,3]\n",
    "    residue_type_ids = torch.tensor(res_types, dtype=torch.long)  # [N]\n",
    "\n",
    "    # KNN 图\n",
    "    N = coords.shape[0]\n",
    "    if N == 1:\n",
    "        edge_index = torch.zeros((2, 0), dtype=torch.long)\n",
    "    else:\n",
    "        # 简单的 O(N^2) 距离，数据规模不大时可以接受\n",
    "        dist_mat = torch.cdist(coords, coords)  # [N,N]\n",
    "        knn = min(K_NEIGHBORS, N - 1)\n",
    "        _, knn_idx = torch.topk(-dist_mat, k=knn+1, dim=-1)  # +1 包含自己\n",
    "\n",
    "        rows = []\n",
    "        cols = []\n",
    "        for i in range(N):\n",
    "            for j in knn_idx[i].tolist():\n",
    "                if i == j:\n",
    "                    continue\n",
    "                rows.append(i)\n",
    "                cols.append(j)\n",
    "        edge_index = torch.tensor([rows, cols], dtype=torch.long)  # [2,E]\n",
    "\n",
    "    return chain_ids, resnums, coords, residue_type_ids, edge_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3341e8",
   "metadata": {},
   "source": [
    "把图打包成 PyG Data，并标注 binding 节点（Code）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad6435c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pyg_data_for_group(pdb_dir: Path, group_key, group_rows, protein_chains=None):\n",
    "    \"\"\"\n",
    "    对一个 (pdb, ligand) group：\n",
    "    - 从对应 PDB 构建 Cα 图；\n",
    "    - 根据 binding_sites 标记 binding 残基；\n",
    "    - 返回 PyG Data（暂时只包含 pos、residue_type、y）。\n",
    "    \"\"\"\n",
    "    pdb_id, lig_resname, lig_chain, lig_resnum = group_key\n",
    "    pdb_path = pdb_dir / f\"{pdb_id}.pdb\"\n",
    "    if not pdb_path.exists():\n",
    "        print(f\"PDB 文件不存在：{pdb_path}\")\n",
    "        return None\n",
    "\n",
    "    node_chain_ids, node_resnums, coords, res_type_ids, edge_index = build_ca_graph_from_pdb(\n",
    "        pdb_path, protein_chains=protein_chains\n",
    "    )\n",
    "    if coords is None:\n",
    "        print(f\"在 {pdb_path} 中未找到蛋白 Cα 节点。\")\n",
    "        return None\n",
    "\n",
    "    N = coords.shape[0]\n",
    "\n",
    "    # 构建一个 (chain, resnum) -> node_idx 的映射\n",
    "    index_map = {}\n",
    "    for i, (cid, rnum) in enumerate(zip(node_chain_ids, node_resnums)):\n",
    "        index_map[(cid, int(rnum))] = i\n",
    "\n",
    "    # 生成 binding 标签\n",
    "    y = torch.zeros(N, dtype=torch.long)\n",
    "    for row in group_rows:\n",
    "        cid = str(row[\"protein_chain\"])\n",
    "        rnum = int(row[\"protein_resnum\"])\n",
    "        idx = index_map.get((cid, rnum))\n",
    "        if idx is not None:\n",
    "            y[idx] = 1\n",
    "\n",
    "    data = Data()\n",
    "    data.pos = coords               # [N,3]\n",
    "    data.residue_type = res_type_ids  # [N]\n",
    "    data.edge_index = edge_index    # [2,E]\n",
    "    data.y = y                      # [N], 0/1 binding 标签\n",
    "\n",
    "    # 额外存一份 metadata（可选）\n",
    "    data.pdb_id = pdb_id\n",
    "    data.ligand_resname = lig_resname\n",
    "    data.ligand_chain = lig_chain\n",
    "    data.ligand_resnum = int(lig_resnum)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf569663",
   "metadata": {},
   "source": [
    "Cell 7：构建 ProteinFeaturiser 并特征化（Code）\n",
    "注意：这个精简版 gcpnet 的 \n",
    "ProteinFeaturiser\n",
    " 期望有 coords，并通过 representation=\"CA\" 把 coords 的第 1 个原子作为 Cα。我们目前只有 pos（Cα）。为了简单起步，可以先绕过 coords，直接用 pos + 自己写的简单几何特征；或者我们给 coords 伪造一个形状 [N, 2, 3]，让 index 1 是 pos。\n",
    "\n",
    "这里给出“简单兼容方案”：构造假的 coords，只放一个坐标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c3374bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_batch_for_featuriser(data_list):\n",
    "    \"\"\"\n",
    "    将多个 Data 合并成 Batch，并构造 coords / seq_pos 等字段，让 ProteinFeaturiser 可以工作。\n",
    "\n",
    "    - coords: [N, 2, 3]，index 1 = Cα 坐标，index 0 = 零向量\n",
    "    - pos   : [N, 3]    暂时用 Cα 坐标（会被 representation='CA' 再次覆盖）\n",
    "    - seq_pos: [N]      简单用 0..N-1，当作序列位置（跨图时按 concat 之后的索引）\n",
    "    \"\"\"\n",
    "    batch = Batch.from_data_list(data_list)   # 自动合并 pos, residue_type, edge_index, y\n",
    "\n",
    "    # 用 batch.pos 作为 Cα 坐标\n",
    "    pos = batch.pos                           # [N,3]\n",
    "    zeros = torch.zeros_like(pos)\n",
    "    coords = torch.stack([zeros, pos], dim=1)  # [N,2,3]，index 1 是 Cα\n",
    "\n",
    "    batch.coords = coords\n",
    "    # 这里也可以给一个简单的序列位置索引\n",
    "    batch.seq_pos = torch.arange(pos.size(0), dtype=torch.long)\n",
    "\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef206742",
   "metadata": {},
   "source": [
    "## Part 2：构建配体图 ligand_graph（原子级图）\n",
    "\n",
    "目标：\n",
    "- 对于每个 (pdb, ligand) 样本，从 PDB 中提取该配体残基的所有原子；\n",
    "- 构建一个原子级别的图：\n",
    "  - 节点：配体原子（坐标=原子坐标；类型=原子类型 ID）；\n",
    "  - 边：基于原子坐标的 KNN 图；\n",
    "- 该图将作为 GCPNet encoder 的输入，用于获得配体 embedding。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "432f3dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 配体原子类型映射（简单版本）\n",
    "ATOM_SYMBOL_TO_ID = {\n",
    "    \"C\": 0,\n",
    "    \"N\": 1,\n",
    "    \"O\": 2,\n",
    "    \"S\": 3,\n",
    "    \"P\": 4,\n",
    "    \"F\": 5,\n",
    "    \"Cl\": 6,\n",
    "    \"Br\": 7,\n",
    "    \"I\": 8,\n",
    "}\n",
    "LIG_UNKNOWN_ATOM_ID = len(ATOM_SYMBOL_TO_ID)\n",
    "\n",
    "\n",
    "def build_ligand_graph_from_pdb(\n",
    "    pdb_path: Path,\n",
    "    lig_resname: str,\n",
    "    lig_chain: str,\n",
    "    lig_resnum: int,\n",
    "    k_neighbors: int = 8,\n",
    ") -> Data | None:\n",
    "    \"\"\"从 PDB 中为指定配体构建原子级图。\n",
    "\n",
    "    - 节点：该配体残基中的所有原子；\n",
    "    - 特征：atom_type（整数 ID）；\n",
    "    - 坐标：原子在 PDB 中的 3D 坐标；\n",
    "    - 边：基于坐标的 KNN 图。\n",
    "    \"\"\"\n",
    "    structure = parser.get_structure(pdb_path.stem, str(pdb_path))\n",
    "    model = next(structure.get_models())\n",
    "\n",
    "    if lig_chain.strip() == \"\" or lig_chain.lower() == \"nan\":\n",
    "        lig_chain_id = \" \"\n",
    "    else:\n",
    "        lig_chain_id = lig_chain\n",
    "\n",
    "    atom_coords = []\n",
    "    atom_types = []\n",
    "\n",
    "    for chain in model:\n",
    "        if chain.id != lig_chain_id:\n",
    "            continue\n",
    "        for residue in chain:\n",
    "            hetfield, resseq, icode = residue.id\n",
    "            if not hetfield.strip():  # 只看 HETATM\n",
    "                continue\n",
    "            if residue.get_resname().strip() != lig_resname.strip():\n",
    "                continue\n",
    "            if int(resseq) != int(lig_resnum):\n",
    "                continue\n",
    "\n",
    "            # 命中了目标配体残基\n",
    "            for atom in residue:\n",
    "                coord = atom.coord\n",
    "                atom_coords.append(coord)\n",
    "\n",
    "                # 原子符号通常为 atom.element，如果为空则用名字首字母\n",
    "                symbol = getattr(atom, \"element\", \"\").strip()\n",
    "                if not symbol:\n",
    "                    name = atom.get_name().strip()\n",
    "                    symbol = name[0].upper() if name else \"C\"\n",
    "\n",
    "                atom_types.append(ATOM_SYMBOL_TO_ID.get(symbol, LIG_UNKNOWN_ATOM_ID))\n",
    "\n",
    "    if not atom_coords:\n",
    "        return None\n",
    "\n",
    "    coords = torch.tensor(np.stack(atom_coords, axis=0), dtype=torch.float32)  # [N,3]\n",
    "    atom_type_ids = torch.tensor(atom_types, dtype=torch.long)\n",
    "\n",
    "    N = coords.shape[0]\n",
    "    if N == 1:\n",
    "        edge_index = torch.zeros((2, 0), dtype=torch.long)\n",
    "    else:\n",
    "        dist_mat = torch.cdist(coords, coords)\n",
    "        k = min(k_neighbors, N - 1)\n",
    "        _, knn_idx = torch.topk(-dist_mat, k=k + 1, dim=-1)\n",
    "\n",
    "        rows, cols = [], []\n",
    "        for i in range(N):\n",
    "            for j in knn_idx[i].tolist():\n",
    "                if i == j:\n",
    "                    continue\n",
    "                rows.append(i)\n",
    "                cols.append(j)\n",
    "        edge_index = torch.tensor([rows, cols], dtype=torch.long)\n",
    "\n",
    "    lig = Data()\n",
    "    lig.pos = coords\n",
    "    lig.atom_type = atom_type_ids\n",
    "    lig.edge_index = edge_index\n",
    "\n",
    "    return lig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c14fa3",
   "metadata": {},
   "source": [
    "## Part 3：构建蛋白–配体相互作用图 interaction_graph\n",
    "\n",
    "目标：\n",
    "- 在同一张图中同时包含：\n",
    "  - binding 残基的 Cα（蛋白侧节点）；\n",
    "  - 配体的原子（配体侧节点）；\n",
    "- 边包括：\n",
    "  - 残基–残基（binding 子图的 KNN）；\n",
    "  - 残基–配体（每个 binding 残基连接到若干最近的配体原子）；\n",
    "  - （可选）配体–配体（沿用配体图中的边）。\n",
    "\n",
    "这张图将捕获真正的“蛋白–配体对”的几何关系。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c6c8f776",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_interaction_graph(\n",
    "    protein_data: Data,\n",
    "    ligand_data: Data,\n",
    "    k_residue_residue: int = 8,\n",
    "    k_residue_ligand: int = 4,\n",
    ") -> Data:\n",
    "    \"\"\"构建蛋白–配体相互作用图。\n",
    "\n",
    "    - 节点：binding 残基 Cα + 配体原子；\n",
    "    - 特征：\n",
    "      - 对于蛋白节点：使用 residue_type 作为类型 ID；\n",
    "      - 对于配体节点：使用 atom_type 作为类型 ID（平移到同一编号空间）；\n",
    "    - 边：残基–残基 KNN、残基–配体最近邻、配体–配体 KNN（复用 ligand_graph）。\n",
    "    \"\"\"\n",
    "    # 1) 取蛋白侧 binding 残基节点\n",
    "    pos_prot = protein_data.pos  # [N_res,3]\n",
    "    res_type = protein_data.residue_type  # [N_res]\n",
    "    y = protein_data.y  # [N_res]\n",
    "\n",
    "    binding_mask = (y > 0)\n",
    "    if not binding_mask.any():\n",
    "        # 如果没有 binding 残基，退化为仅配体图\n",
    "        inter = ligand_data.clone()\n",
    "        inter.node_type = torch.ones(inter.pos.size(0), dtype=torch.long)  # 全部视为配体节点\n",
    "        return inter\n",
    "\n",
    "    pos_bind = pos_prot[binding_mask]        # [Nb,3]\n",
    "    res_type_bind = res_type[binding_mask]   # [Nb]\n",
    "\n",
    "    # 2) 配体原子\n",
    "    pos_lig = ligand_data.pos               # [Nl,3]\n",
    "    atom_type = ligand_data.atom_type       # [Nl]\n",
    "\n",
    "    # 3) 统一节点特征空间\n",
    "    #   简单做法：蛋白残基类型 ID 保持原样，配体原子类型 ID 平移一个偏移量，\n",
    "    #   之后在 GNN 中用 one-hot 编码。\n",
    "    residue_type_offset = 0\n",
    "    atom_type_offset = res_type_bind.max().item() + 1\n",
    "\n",
    "    node_type_ids = torch.cat(\n",
    "        [\n",
    "            res_type_bind + residue_type_offset,\n",
    "            atom_type + atom_type_offset,\n",
    "        ],\n",
    "        dim=0,\n",
    "    )  # [Nb + Nl]\n",
    "\n",
    "    # 4) 组合坐标\n",
    "    pos_all = torch.cat([pos_bind, pos_lig], dim=0)  # [Nb+Nl,3]\n",
    "    Nb = pos_bind.size(0)\n",
    "    Nl = pos_lig.size(0)\n",
    "\n",
    "    # 5) 残基–残基 KNN\n",
    "    if Nb > 1:\n",
    "        dist_rr = torch.cdist(pos_bind, pos_bind)\n",
    "        k_rr = min(k_residue_residue, Nb - 1)\n",
    "        _, knn_idx_rr = torch.topk(-dist_rr, k=k_rr + 1, dim=-1)\n",
    "        rr_rows, rr_cols = [], []\n",
    "        for i in range(Nb):\n",
    "            for j in knn_idx_rr[i].tolist():\n",
    "                if i == j:\n",
    "                    continue\n",
    "                rr_rows.append(i)\n",
    "                rr_cols.append(j)\n",
    "        edge_rr = torch.tensor([rr_rows, rr_cols], dtype=torch.long)\n",
    "    else:\n",
    "        edge_rr = torch.zeros((2, 0), dtype=torch.long)\n",
    "\n",
    "    # 6) 残基–配体最近邻\n",
    "    if Nb > 0 and Nl > 0:\n",
    "        dist_rl = torch.cdist(pos_bind, pos_lig)  # [Nb, Nl]\n",
    "        k_rl = min(k_residue_ligand, Nl)\n",
    "        _, knn_idx_rl = torch.topk(-dist_rl, k=k_rl, dim=-1)\n",
    "        rl_rows, rl_cols = [], []\n",
    "        for i in range(Nb):\n",
    "            for j in knn_idx_rl[i].tolist():\n",
    "                rl_rows.append(i)\n",
    "                rl_cols.append(Nb + j)  # 配体节点索引偏移 Nb\n",
    "        edge_rl = torch.tensor([rl_rows, rl_cols], dtype=torch.long)\n",
    "    else:\n",
    "        edge_rl = torch.zeros((2, 0), dtype=torch.long)\n",
    "\n",
    "    # 7) 配体–配体边：直接复用 ligand_data.edge_index，并整体索引偏移 Nb\n",
    "    if ligand_data.edge_index.numel() > 0:\n",
    "        edge_ll = ligand_data.edge_index + Nb\n",
    "    else:\n",
    "        edge_ll = torch.zeros((2, 0), dtype=torch.long)\n",
    "\n",
    "    # 合并所有边\n",
    "    edge_index = torch.cat([edge_rr, edge_rl, edge_ll], dim=1)\n",
    "\n",
    "    inter = Data()\n",
    "    inter.pos = pos_all\n",
    "    inter.node_type_id = node_type_ids\n",
    "    inter.edge_index = edge_index\n",
    "\n",
    "    return inter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90629595",
   "metadata": {},
   "source": [
    "## Part 4：使用完整版 GCPNet encoder 对三类图进行编码\n",
    "\n",
    "这里我们**不再裁剪 gcpnet 源码**，而是：\n",
    "\n",
    "- 使用你提供的 `config_gcpnet_encoder.yaml` 中的 `encoder.module_cfg/model_cfg/layer_cfg`；\n",
    "- 用 `OmegaConf` 读取这些配置，初始化原版 `GCPNetModel`；\n",
    "- 按照 GCPNet 预期的字段组织三种图的 `Batch`：\n",
    "  - `h` / `chi`（节点标量/向量特征）；\n",
    "  - `e` / `xi`（边标量/向量特征）；\n",
    "  - `pos`（节点坐标）、`edge_index`（边列表）、`batch`（图索引）；\n",
    "- 分别定义：\n",
    "  - `encode_protein_graph`：对蛋白图进行编码，并在 binding 残基上 pooling；\n",
    "  - `encode_ligand_graph`：对配体图进行编码，并在所有原子上 pooling；\n",
    "  - `encode_interaction_graph`：对蛋白–配体相互作用图进行编码，并在所有节点上 pooling。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "279ef1c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'features': {'module': 'models.gcpnet.features.factory.ProteinFeaturiser', 'kwargs': {'representation': 'CA', 'scalar_node_features': ['amino_acid_one_hot', 'sequence_positional_encoding', 'alpha', 'kappa', 'dihedrals'], 'vector_node_features': ['orientation'], 'edge_types': ['knn_16'], 'scalar_edge_features': ['edge_distance'], 'vector_edge_features': ['edge_vectors']}}, 'task': {'transform': None}, 'encoder': {'module': 'models.gcpnet.models.graph_encoders.gcpnet.GCPNetModel', 'kwargs': {'num_layers': 6, 'emb_dim': 128, 'node_s_emb_dim': 128, 'node_v_emb_dim': 16, 'edge_s_emb_dim': 32, 'edge_v_emb_dim': 4, 'r_max': 10.0, 'num_rbf': 8, 'activation': 'silu', 'pool': 'sum', 'module_cfg': {'norm_pos_diff': True, 'scalar_gate': 0, 'vector_gate': True, 'scalar_nonlinearity': 'silu', 'vector_nonlinearity': 'silu', 'nonlinearities': ['silu', 'silu'], 'r_max': 10.0, 'num_rbf': 8, 'bottleneck': 4, 'vector_linear': True, 'vector_identity': True, 'default_bottleneck': 4, 'predict_node_positions': False, 'predict_node_rep': True, 'node_positions_weight': 1.0, 'update_positions_with_vector_sum': False, 'enable_e3_equivariance': False, 'pool': 'sum'}, 'model_cfg': {'h_input_dim': 49, 'chi_input_dim': 2, 'e_input_dim': 9, 'xi_input_dim': 1, 'h_hidden_dim': 128, 'chi_hidden_dim': 16, 'e_hidden_dim': 32, 'xi_hidden_dim': 4, 'num_layers': 6, 'dropout': 0.0}, 'layer_cfg': {'pre_norm': False, 'use_gcp_norm': True, 'use_gcp_dropout': True, 'use_scalar_message_attention': True, 'num_feedforward_layers': 2, 'dropout': 0.0, 'nonlinearity_slope': 0.01, 'mp_cfg': {'edge_encoder': False, 'edge_gate': False, 'num_message_layers': 4, 'message_residual': 0, 'message_ff_multiplier': 1, 'self_message': True}}}}, 'top_k': 30, 'num_positional_embeddings': 16}\n"
     ]
    }
   ],
   "source": [
    "from omegaconf import OmegaConf\n",
    "from pprint import pprint\n",
    "\n",
    "CFG_PATH = BASE_DIR / \"config_gcpnet_encoder.yaml\"\n",
    "cfg = OmegaConf.load(str(CFG_PATH))\n",
    "pprint(cfg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f9b6ec8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ GCPNet 编码器初始化成功\n",
      "  - 层数: 6\n",
      "  - 节点标量维度: 128\n",
      "  - 节点向量维度: 16\n",
      "✓ 蛋白质 Featuriser 初始化成功\n",
      "✓ 编码函数定义完成\n"
     ]
    }
   ],
   "source": [
    "# 4.1 从 YAML 加载完整版 GCPNet encoder 配置并初始化模型\n",
    "\n",
    "from omegaconf import OmegaConf\n",
    "from types import SimpleNamespace\n",
    "\n",
    "CFG_PATH = BASE_DIR / \"config_gcpnet_encoder.yaml\"\n",
    "\n",
    "cfg = OmegaConf.load(str(CFG_PATH))\n",
    "\n",
    "encoder_cfg = cfg.encoder\n",
    "\n",
    "# 先转换为普通字典避免循环引用\n",
    "enc_kwargs_dict = OmegaConf.to_container(encoder_cfg.kwargs, resolve=True)\n",
    "\n",
    "\n",
    "def dict_to_namespace(d):\n",
    "    \"\"\"递归地将字典转换为 SimpleNamespace，支持属性访问但避免 OmegaConf 的循环引用问题\"\"\"\n",
    "    if isinstance(d, dict):\n",
    "        return SimpleNamespace(**{k: dict_to_namespace(v) for k, v in d.items()})\n",
    "    elif isinstance(d, list):\n",
    "        return [dict_to_namespace(item) for item in d]\n",
    "    else:\n",
    "        return d\n",
    "\n",
    "\n",
    "# 将嵌套配置转换为 SimpleNamespace（支持 .attribute 访问，但避免递归问题）\n",
    "enc_kwargs = {\n",
    "    'num_layers': enc_kwargs_dict['num_layers'],\n",
    "    'emb_dim': enc_kwargs_dict['emb_dim'],\n",
    "    'node_s_emb_dim': enc_kwargs_dict['node_s_emb_dim'],\n",
    "    'node_v_emb_dim': enc_kwargs_dict['node_v_emb_dim'],\n",
    "    'edge_s_emb_dim': enc_kwargs_dict['edge_s_emb_dim'],\n",
    "    'edge_v_emb_dim': enc_kwargs_dict['edge_v_emb_dim'],\n",
    "    'r_max': enc_kwargs_dict['r_max'],\n",
    "    'num_rbf': enc_kwargs_dict['num_rbf'],\n",
    "    'activation': enc_kwargs_dict['activation'],\n",
    "    'pool': enc_kwargs_dict['pool'],\n",
    "    'module_cfg': dict_to_namespace(enc_kwargs_dict['module_cfg']),\n",
    "    'model_cfg': dict_to_namespace(enc_kwargs_dict['model_cfg']),\n",
    "    'layer_cfg': dict_to_namespace(enc_kwargs_dict['layer_cfg']),\n",
    "}\n",
    "\n",
    "# 初始化 GCPNet 编码器\n",
    "full_gcpnet_encoder = GCPNetModel(\n",
    "    **enc_kwargs\n",
    ").eval()\n",
    "\n",
    "print(f\"✓ GCPNet 编码器初始化成功\")\n",
    "print(f\"  - 层数: {enc_kwargs['num_layers']}\")\n",
    "print(f\"  - 节点标量维度: {enc_kwargs['node_s_emb_dim']}\")\n",
    "print(f\"  - 节点向量维度: {enc_kwargs['node_v_emb_dim']}\")\n",
    "\n",
    "# 创建一个简化的 featuriser（不使用需要 _slice_dict 的 vector node features）\n",
    "featuriser_for_protein = ProteinFeaturiser(\n",
    "    representation=\"CA\",\n",
    "    scalar_node_features=[\"amino_acid_one_hot\"],\n",
    "    vector_node_features=[],  # 移除 orientation 等需要 _slice_dict 的特征\n",
    "    edge_types=[\"knn_16\"],\n",
    "    scalar_edge_features=[\"edge_distance\"],\n",
    "    vector_edge_features=[\"edge_vectors\"],\n",
    ")\n",
    "\n",
    "print(f\"✓ 蛋白质 Featuriser 初始化成功\")\n",
    "\n",
    "\n",
    "def _build_gcpnet_batch_from_featurised_batch(batch: Batch) -> Batch:\n",
    "    \"\"\"将 ProteinFeaturiser 产生的字段整理为 GCPNetModel 期望的命名。\n",
    "\n",
    "    约定：\n",
    "    - featuriser(batch) 后：\n",
    "      * batch.x             -> 节点标量特征 h\n",
    "      * batch.x_vector_attr -> 节点向量特征 chi（如果有）\n",
    "      * batch.edge_attr     -> 边标量特征 e\n",
    "      * batch.edge_vector_attr -> 边向量特征 xi\n",
    "      * batch.pos / edge_index / batch 已经就绪\n",
    "    \"\"\"\n",
    "    batch.h = batch.x\n",
    "    # 如果没有向量特征，创建一个空的\n",
    "    batch.chi = getattr(batch, \"x_vector_attr\", torch.zeros(batch.x.size(0), 0, 3, device=batch.x.device))\n",
    "    batch.e = getattr(batch, \"edge_attr\", torch.zeros(batch.edge_index.size(1), 1, device=batch.x.device))\n",
    "    batch.xi = getattr(batch, \"edge_vector_attr\", torch.zeros(batch.edge_index.size(1), 0, 3, device=batch.x.device))\n",
    "    return batch\n",
    "\n",
    "\n",
    "def _pool_by_graph(node_emb: torch.Tensor, batch_index: torch.Tensor, reduce: str = \"mean\") -> torch.Tensor:\n",
    "    \"\"\"简单的按图 pooling，使用 PyTorch 实现 mean/sum。\"\"\"\n",
    "    num_graphs = int(batch_index.max().item()) + 1 if batch_index.numel() > 0 else 0\n",
    "    if num_graphs == 0:\n",
    "        return node_emb.new_zeros((0, node_emb.size(-1)))\n",
    "    out = []\n",
    "    for g in range(num_graphs):\n",
    "        m = (batch_index == g)\n",
    "        if not m.any():\n",
    "            out.append(node_emb.new_zeros((node_emb.size(-1),)))\n",
    "        else:\n",
    "            if reduce == \"sum\":\n",
    "                out.append(node_emb[m].sum(dim=0))\n",
    "            else:\n",
    "                out.append(node_emb[m].mean(dim=0))\n",
    "    return torch.stack(out, dim=0)\n",
    "\n",
    "\n",
    "def encode_protein_graph(batch: Batch) -> torch.Tensor:\n",
    "    \"\"\"对蛋白 Batch 进行编码：对 binding 残基节点做 mean pooling。\"\"\"\n",
    "    # 使用简化的 featuriser\n",
    "    batch = featuriser_for_protein(batch)\n",
    "    batch = _build_gcpnet_batch_from_featurised_batch(batch)\n",
    "\n",
    "    # 前向：完整版 GCPNetModel 返回 EncoderOutput，包含 \"node_embedding\" / \"graph_embedding\"\n",
    "    with torch.no_grad():\n",
    "        enc_out = full_gcpnet_encoder(batch)\n",
    "    node_emb = enc_out[\"node_embedding\"]  # [N_total, D]\n",
    "\n",
    "    y = batch.y\n",
    "    graph_idx = batch.batch\n",
    "\n",
    "    # 先按 binding 掩码池化；无 binding 时退化为所有节点 mean\n",
    "    num_graphs = int(graph_idx.max().item()) + 1\n",
    "    h_list = []\n",
    "    for g in range(num_graphs):\n",
    "        mask_g = (graph_idx == g)\n",
    "        x_g = node_emb[mask_g]\n",
    "        y_g = y[mask_g]\n",
    "        if x_g.numel() == 0:\n",
    "            h_list.append(node_emb.new_zeros(enc_kwargs['node_s_emb_dim']))\n",
    "            continue\n",
    "        mask_binding = (y_g > 0)\n",
    "        if mask_binding.any():\n",
    "            h = x_g[mask_binding].mean(dim=0)\n",
    "        else:\n",
    "            h = x_g.mean(dim=0)\n",
    "        h_list.append(h)\n",
    "\n",
    "    return torch.stack(h_list, dim=0)\n",
    "\n",
    "print(f\"✓ 编码函数定义完成\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7dbee596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始配置文件中的输入维度：\n",
      "  - h_input_dim: 49\n",
      "  - chi_input_dim: 2\n",
      "  - e_input_dim: 9\n",
      "  - xi_input_dim: 1\n",
      "\n",
      "✓ 蛋白质 Featuriser 初始化成功\n",
      "\n",
      "检测 featuriser 实际输出维度...\n",
      "  - 实际节点标量特征维度 (h): 23\n",
      "  - 实际节点向量特征维度 (chi): 0\n",
      "  - 实际边标量特征维度 (e): 1 → 9 (GCPNet内部会添加8维RBF)\n",
      "  - 实际边向量特征维度 (xi): 1\n",
      "\n",
      "更新配置以匹配 featuriser 输出...\n",
      "✓ 已更新配置:\n",
      "  - h_input_dim: 49 → 23\n",
      "  - chi_input_dim: 2 → 0\n",
      "  - e_input_dim: 9 (保持不变)\n",
      "  - xi_input_dim: 1 (保持不变)\n",
      "\n",
      "初始化 GCPNet 编码器...\n",
      "✓ GCPNet 编码器初始化成功\n",
      "  - 层数: 6\n",
      "  - 节点标量嵌入维度: 128\n",
      "  - 节点向量嵌入维度: 16\n",
      "\n",
      "✓ 编码函数定义完成\n"
     ]
    }
   ],
   "source": [
    "# 4.1 从 YAML 加载完整版 GCPNet encoder 配置并初始化模型\n",
    "\n",
    "from omegaconf import OmegaConf\n",
    "from types import SimpleNamespace\n",
    "\n",
    "CFG_PATH = BASE_DIR / \"config_gcpnet_encoder.yaml\"\n",
    "\n",
    "cfg = OmegaConf.load(str(CFG_PATH))\n",
    "encoder_cfg = cfg.encoder\n",
    "\n",
    "# 先转换为普通字典避免循环引用\n",
    "enc_kwargs_dict = OmegaConf.to_container(encoder_cfg.kwargs, resolve=True)\n",
    "\n",
    "print(\"原始配置文件中的输入维度：\")\n",
    "print(f\"  - h_input_dim: {enc_kwargs_dict['model_cfg']['h_input_dim']}\")\n",
    "print(f\"  - chi_input_dim: {enc_kwargs_dict['model_cfg']['chi_input_dim']}\")\n",
    "print(f\"  - e_input_dim: {enc_kwargs_dict['model_cfg']['e_input_dim']}\")\n",
    "print(f\"  - xi_input_dim: {enc_kwargs_dict['model_cfg']['xi_input_dim']}\")\n",
    "\n",
    "\n",
    "def dict_to_namespace(d):\n",
    "    \"\"\"递归地将字典转换为 SimpleNamespace，支持属性访问但避免 OmegaConf 的循环引用问题\"\"\"\n",
    "    if isinstance(d, dict):\n",
    "        return SimpleNamespace(**{k: dict_to_namespace(v) for k, v in d.items()})\n",
    "    elif isinstance(d, list):\n",
    "        return [dict_to_namespace(item) for item in d]\n",
    "    else:\n",
    "        return d\n",
    "\n",
    "\n",
    "# 创建一个简化的 featuriser（不使用需要 _slice_dict 的 vector node features）\n",
    "featuriser_for_protein = ProteinFeaturiser(\n",
    "    representation=\"CA\",\n",
    "    scalar_node_features=[\"amino_acid_one_hot\"],\n",
    "    vector_node_features=[],  # 移除 orientation 等需要 _slice_dict 的特征\n",
    "    edge_types=[\"knn_16\"],\n",
    "    scalar_edge_features=[\"edge_distance\"],\n",
    "    vector_edge_features=[\"edge_vectors\"],\n",
    ")\n",
    "\n",
    "print(f\"\\n✓ 蛋白质 Featuriser 初始化成功\")\n",
    "\n",
    "# 测试 featuriser 输出维度\n",
    "print(\"\\n检测 featuriser 实际输出维度...\")\n",
    "test_data = Data()\n",
    "test_data.pos = torch.randn(5, 3)\n",
    "test_data.residue_type = torch.randint(0, 20, (5,))\n",
    "test_data.edge_index = torch.tensor([[0, 1, 2], [1, 2, 3]], dtype=torch.long)\n",
    "test_data.y = torch.zeros(5, dtype=torch.long)\n",
    "\n",
    "test_batch = Batch.from_data_list([test_data])\n",
    "test_batch.coords = torch.stack([torch.zeros_like(test_batch.pos), test_batch.pos], dim=1)\n",
    "test_batch.seq_pos = torch.arange(test_batch.pos.size(0), dtype=torch.long)\n",
    "\n",
    "test_batch = featuriser_for_protein(test_batch)\n",
    "actual_h_dim = test_batch.x.size(-1)\n",
    "actual_chi_dim = test_batch.x_vector_attr.size(1) if hasattr(test_batch, 'x_vector_attr') and test_batch.x_vector_attr is not None else 0\n",
    "\n",
    "print(f\"  - 实际节点标量特征维度 (h): {actual_h_dim}\")\n",
    "print(f\"  - 实际节点向量特征维度 (chi): {actual_chi_dim}\")\n",
    "print(f\"  - 实际边标量特征维度 (e): 1 → 9 (GCPNet内部会添加8维RBF)\")\n",
    "print(f\"  - 实际边向量特征维度 (xi): 1\")\n",
    "\n",
    "# 更新 model_cfg 以匹配实际特征维度\n",
    "print(f\"\\n更新配置以匹配 featuriser 输出...\")\n",
    "enc_kwargs_dict['model_cfg']['h_input_dim'] = actual_h_dim\n",
    "enc_kwargs_dict['model_cfg']['chi_input_dim'] = actual_chi_dim\n",
    "# e_input_dim 和 xi_input_dim 保持不变（GCPNet会自动处理）\n",
    "\n",
    "print(f\"✓ 已更新配置:\")\n",
    "print(f\"  - h_input_dim: 49 → {actual_h_dim}\")\n",
    "print(f\"  - chi_input_dim: 2 → {actual_chi_dim}\")\n",
    "print(f\"  - e_input_dim: 9 (保持不变)\")\n",
    "print(f\"  - xi_input_dim: 1 (保持不变)\")\n",
    "\n",
    "# 将嵌套配置转换为 SimpleNamespace\n",
    "enc_kwargs = {\n",
    "    'num_layers': enc_kwargs_dict['num_layers'],\n",
    "    'emb_dim': enc_kwargs_dict['emb_dim'],\n",
    "    'node_s_emb_dim': enc_kwargs_dict['node_s_emb_dim'],\n",
    "    'node_v_emb_dim': enc_kwargs_dict['node_v_emb_dim'],\n",
    "    'edge_s_emb_dim': enc_kwargs_dict['edge_s_emb_dim'],\n",
    "    'edge_v_emb_dim': enc_kwargs_dict['edge_v_emb_dim'],\n",
    "    'r_max': enc_kwargs_dict['r_max'],\n",
    "    'num_rbf': enc_kwargs_dict['num_rbf'],\n",
    "    'activation': enc_kwargs_dict['activation'],\n",
    "    'pool': enc_kwargs_dict['pool'],\n",
    "    'module_cfg': dict_to_namespace(enc_kwargs_dict['module_cfg']),\n",
    "    'model_cfg': dict_to_namespace(enc_kwargs_dict['model_cfg']),\n",
    "    'layer_cfg': dict_to_namespace(enc_kwargs_dict['layer_cfg']),\n",
    "}\n",
    "\n",
    "# 初始化 GCPNet 编码器（在更新配置之后）\n",
    "print(f\"\\n初始化 GCPNet 编码器...\")\n",
    "full_gcpnet_encoder = GCPNetModel(\n",
    "    **enc_kwargs\n",
    ").eval()\n",
    "\n",
    "print(f\"✓ GCPNet 编码器初始化成功\")\n",
    "print(f\"  - 层数: {enc_kwargs['num_layers']}\")\n",
    "print(f\"  - 节点标量嵌入维度: {enc_kwargs['node_s_emb_dim']}\")\n",
    "print(f\"  - 节点向量嵌入维度: {enc_kwargs['node_v_emb_dim']}\")\n",
    "\n",
    "\n",
    "def _ensure_batch_vector_attrs(batch: Batch) -> Batch:\n",
    "    \"\"\"确保 batch 有 GCPNetModel 期望的所有向量属性。\"\"\"\n",
    "    if not hasattr(batch, \"x_vector_attr\") or batch.x_vector_attr is None:\n",
    "        batch.x_vector_attr = torch.zeros(batch.x.size(0), 0, 3, device=batch.x.device)\n",
    "    if not hasattr(batch, \"edge_vector_attr\") or batch.edge_vector_attr is None:\n",
    "        batch.edge_vector_attr = torch.zeros(batch.edge_index.size(1), 0, 3, device=batch.x.device)\n",
    "    return batch\n",
    "\n",
    "\n",
    "def _pool_by_graph(node_emb: torch.Tensor, batch_index: torch.Tensor, reduce: str = \"mean\") -> torch.Tensor:\n",
    "    \"\"\"简单的按图 pooling，使用 PyTorch 实现 mean/sum。\"\"\"\n",
    "    num_graphs = int(batch_index.max().item()) + 1 if batch_index.numel() > 0 else 0\n",
    "    if num_graphs == 0:\n",
    "        return node_emb.new_zeros((0, node_emb.size(-1)))\n",
    "    out = []\n",
    "    for g in range(num_graphs):\n",
    "        m = (batch_index == g)\n",
    "        if not m.any():\n",
    "            out.append(node_emb.new_zeros((node_emb.size(-1),)))\n",
    "        else:\n",
    "            if reduce == \"sum\":\n",
    "                out.append(node_emb[m].sum(dim=0))\n",
    "            else:\n",
    "                out.append(node_emb[m].mean(dim=0))\n",
    "    return torch.stack(out, dim=0)\n",
    "\n",
    "\n",
    "def encode_protein_graph(batch: Batch) -> torch.Tensor:\n",
    "    \"\"\"对蛋白 Batch 进行编码：对 binding 残基节点做 mean pooling。\"\"\"\n",
    "    # 使用简化的 featuriser\n",
    "    batch = featuriser_for_protein(batch)\n",
    "    \n",
    "    # 确保 batch 有所有必需的向量属性\n",
    "    batch = _ensure_batch_vector_attrs(batch)\n",
    "\n",
    "    # 前向：完整版 GCPNetModel 返回 EncoderOutput，包含 \"node_embedding\" / \"graph_embedding\"\n",
    "    with torch.no_grad():\n",
    "        enc_out = full_gcpnet_encoder(batch)\n",
    "    node_emb = enc_out[\"node_embedding\"]  # [N_total, D]\n",
    "\n",
    "    y = batch.y\n",
    "    graph_idx = batch.batch\n",
    "\n",
    "    # 先按 binding 掩码池化；无 binding 时退化为所有节点 mean\n",
    "    num_graphs = int(graph_idx.max().item()) + 1\n",
    "    h_list = []\n",
    "    for g in range(num_graphs):\n",
    "        mask_g = (graph_idx == g)\n",
    "        x_g = node_emb[mask_g]\n",
    "        y_g = y[mask_g]\n",
    "        if x_g.numel() == 0:\n",
    "            h_list.append(node_emb.new_zeros(enc_kwargs['node_s_emb_dim']))\n",
    "            continue\n",
    "        mask_binding = (y_g > 0)\n",
    "        if mask_binding.any():\n",
    "            h = x_g[mask_binding].mean(dim=0)\n",
    "        else:\n",
    "            h = x_g.mean(dim=0)\n",
    "        h_list.append(h)\n",
    "\n",
    "    return torch.stack(h_list, dim=0)\n",
    "\n",
    "print(f\"\\n✓ 编码函数定义完成\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a71f0aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2 定义 encode_ligand_graph：对配体原子图进行编码\n",
    "\n",
    "def encode_ligand_graph(ligand_data_list: List[Data]) -> torch.Tensor:\n",
    "    \"\"\"对一组配体图编码，对每图的所有原子节点做 mean pooling。\n",
    "    \n",
    "    - 节点特征：对 `atom_type` 做 one-hot，然后 pad 到与蛋白特征相同的维度；\n",
    "    - 边特征：用坐标差构造距离 + 单位向量。\n",
    "    \"\"\"\n",
    "    batch = Batch.from_data_list(ligand_data_list)\n",
    "    \n",
    "    # 构造节点特征：atom_type one-hot\n",
    "    num_atom_types = int(batch.atom_type.max().item()) + 1\n",
    "    x_onehot = torch.nn.functional.one_hot(batch.atom_type, num_classes=num_atom_types).float()\n",
    "    \n",
    "    # Pad 到与蛋白特征相同的维度\n",
    "    target_dim = enc_kwargs['model_cfg'].h_input_dim\n",
    "    if x_onehot.size(-1) < target_dim:\n",
    "        padding = torch.zeros(x_onehot.size(0), target_dim - x_onehot.size(-1), device=x_onehot.device)\n",
    "        batch.x = torch.cat([x_onehot, padding], dim=-1)\n",
    "    elif x_onehot.size(-1) > target_dim:\n",
    "        # 如果维度过大，截断或报错\n",
    "        batch.x = x_onehot[:, :target_dim]\n",
    "    else:\n",
    "        batch.x = x_onehot\n",
    "    \n",
    "    # 构造边特征：距离 + 方向向量\n",
    "    pos = batch.pos  # [N, 3]\n",
    "    row, col = batch.edge_index  # [2, E]\n",
    "    diff = pos[row] - pos[col]  # [E, 3]\n",
    "    dist = torch.norm(diff, dim=-1, keepdim=True)  # [E, 1]\n",
    "    unit = diff / (dist + 1e-8)  # [E, 3] 单位向量\n",
    "    \n",
    "    # 设置 GCPNetModel 期望的属性\n",
    "    batch.edge_attr = dist  # [E, 1] 标量边特征\n",
    "    batch.edge_vector_attr = unit.unsqueeze(-2)  # [E, 1, 3] 向量边特征\n",
    "    batch.x_vector_attr = torch.zeros(batch.x.size(0), 0, 3, device=batch.x.device)  # 配体无向量节点特征\n",
    "    \n",
    "    # 前向编码\n",
    "    with torch.no_grad():\n",
    "        enc_out = full_gcpnet_encoder(batch)\n",
    "    node_emb = enc_out[\"node_embedding\"]  # [N_total, D]\n",
    "    \n",
    "    # 按图 pooling\n",
    "    return _pool_by_graph(node_emb, batch.batch, reduce=\"mean\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0fec79a",
   "metadata": {},
   "source": [
    "## Part 5：整合三类图并导出三重 embedding\n",
    "\n",
    "这一部分将前面构建好的三类图（蛋白 binding 残基图、配体原子图、蛋白–配体相互作用图）通过完整版 GCPNet encoder 编码为三个向量，并在 `compute_triplet_embeddings` 中进行整合：\n",
    "\n",
    "- **蛋白图编码**：先用 `to_batch_for_featuriser` + `encode_protein_graph` 得到蛋白口袋 embedding；\n",
    "- **配体图编码**：用 `encode_ligand_graph` 对配体原子图做 mean pooling 得到配体 embedding；\n",
    "- **相互作用图编码**：用 `encode_interaction_graph` 对蛋白–配体相互作用图做 pooling 得到复合物级 embedding；\n",
    "- 最后将三者拼接，并写入 `binding_embeddings_triplet.csv`，作为下游模型/分析的输入特征。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "93658242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "步骤 1: 检测 ProteinFeaturiser 实际输出维度\n",
      "============================================================\n",
      "✓ Featuriser 实际输出维度:\n",
      "  - 节点标量特征 (h): 23\n",
      "  - 节点向量特征 (chi): 0\n",
      "  - 边标量特征 (e): 1\n",
      "  - 边向量特征 (xi): 1\n",
      "\n",
      "============================================================\n",
      "步骤 2: 检查 YAML 配置文件中的默认维度\n",
      "============================================================\n",
      "配置文件中的默认维度:\n",
      "  - h_input_dim: 49\n",
      "  - chi_input_dim: 2\n",
      "  - e_input_dim: 9\n",
      "  - xi_input_dim: 1\n",
      "\n",
      "============================================================\n",
      "步骤 3: 修正配置并初始化模型\n",
      "============================================================\n",
      "\n",
      "更新配置维度以匹配 featuriser 输出...\n",
      "⚠️  注意：GCPNet 会自动将边特征 (1维) + RBF展开 (8维) = 9维\n",
      "   所以 e_input_dim 应保持为 9，不要修改为 1！\n",
      "✓ 更新后的配置维度:\n",
      "  - h_input_dim: 23 (修改: 49 → 23)\n",
      "  - chi_input_dim: 0 (修改: 2 → 0)\n",
      "  - e_input_dim: 9 (保持不变: 1+8 RBF)\n",
      "  - xi_input_dim: 1 (保持不变)\n",
      "\n",
      "初始化 GCPNet 模型...\n",
      "✓ 模型初始化成功！\n",
      "\n",
      "============================================================\n",
      "步骤 4: 测试前向传播\n",
      "============================================================\n",
      "测试 batch 的属性:\n",
      "  - x shape: torch.Size([10, 23])\n",
      "  - x_vector_attr shape: torch.Size([10, 0, 3])\n",
      "  - edge_attr shape: torch.Size([4, 1])\n",
      "  - edge_vector_attr shape: torch.Size([4, 1, 3])\n",
      "✓ 前向传播成功！\n",
      "  - node_embedding shape: torch.Size([10, 128])\n",
      "  - graph_embedding shape: torch.Size([1, 128])\n",
      "\n",
      "============================================================\n",
      "调试完成！所有测试通过。\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "run debug_gcpnet.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb55d9fa",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "106d864f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已保存 50 条三重 embedding 到 c:\\Users\\Administrator\\Desktop\\IGEM\\stage1\\notebook-lab\\binding_embeddings_triplet.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pdb_id</th>\n",
       "      <th>ligand_resname</th>\n",
       "      <th>ligand_chain</th>\n",
       "      <th>ligand_resnum</th>\n",
       "      <th>feat_0</th>\n",
       "      <th>feat_1</th>\n",
       "      <th>feat_2</th>\n",
       "      <th>feat_3</th>\n",
       "      <th>feat_4</th>\n",
       "      <th>feat_5</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_374</th>\n",
       "      <th>feat_375</th>\n",
       "      <th>feat_376</th>\n",
       "      <th>feat_377</th>\n",
       "      <th>feat_378</th>\n",
       "      <th>feat_379</th>\n",
       "      <th>feat_380</th>\n",
       "      <th>feat_381</th>\n",
       "      <th>feat_382</th>\n",
       "      <th>feat_383</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>FAD</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.160192</td>\n",
       "      <td>0.037487</td>\n",
       "      <td>0.343853</td>\n",
       "      <td>0.107562</td>\n",
       "      <td>-0.045167</td>\n",
       "      <td>-0.109482</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015290</td>\n",
       "      <td>0.039096</td>\n",
       "      <td>0.030261</td>\n",
       "      <td>0.059242</td>\n",
       "      <td>0.183268</td>\n",
       "      <td>-0.042948</td>\n",
       "      <td>0.263075</td>\n",
       "      <td>0.095507</td>\n",
       "      <td>-0.121052</td>\n",
       "      <td>0.072660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>UNL</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>-0.140156</td>\n",
       "      <td>0.044201</td>\n",
       "      <td>0.377216</td>\n",
       "      <td>0.274628</td>\n",
       "      <td>-0.066483</td>\n",
       "      <td>0.099652</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044303</td>\n",
       "      <td>-0.060594</td>\n",
       "      <td>0.118736</td>\n",
       "      <td>-0.085967</td>\n",
       "      <td>0.095112</td>\n",
       "      <td>-0.050972</td>\n",
       "      <td>0.074142</td>\n",
       "      <td>-0.077221</td>\n",
       "      <td>0.015196</td>\n",
       "      <td>0.454500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>UNL</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>-0.174216</td>\n",
       "      <td>0.054912</td>\n",
       "      <td>0.565381</td>\n",
       "      <td>0.199195</td>\n",
       "      <td>0.056334</td>\n",
       "      <td>-0.095419</td>\n",
       "      <td>...</td>\n",
       "      <td>0.074319</td>\n",
       "      <td>-0.054754</td>\n",
       "      <td>0.080264</td>\n",
       "      <td>-0.049534</td>\n",
       "      <td>0.192698</td>\n",
       "      <td>-0.046946</td>\n",
       "      <td>0.171882</td>\n",
       "      <td>0.023477</td>\n",
       "      <td>-0.068335</td>\n",
       "      <td>0.349761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000</td>\n",
       "      <td>UNL</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>-0.210572</td>\n",
       "      <td>0.193983</td>\n",
       "      <td>0.098806</td>\n",
       "      <td>-0.067299</td>\n",
       "      <td>0.027583</td>\n",
       "      <td>-0.232041</td>\n",
       "      <td>...</td>\n",
       "      <td>0.047724</td>\n",
       "      <td>0.078645</td>\n",
       "      <td>-0.045543</td>\n",
       "      <td>0.011250</td>\n",
       "      <td>0.219708</td>\n",
       "      <td>0.067847</td>\n",
       "      <td>0.251348</td>\n",
       "      <td>0.196277</td>\n",
       "      <td>-0.032712</td>\n",
       "      <td>0.107715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1001</td>\n",
       "      <td>UNL</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>-0.139574</td>\n",
       "      <td>0.238269</td>\n",
       "      <td>0.317292</td>\n",
       "      <td>0.029820</td>\n",
       "      <td>0.067032</td>\n",
       "      <td>0.024362</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069117</td>\n",
       "      <td>0.075436</td>\n",
       "      <td>0.151512</td>\n",
       "      <td>-0.037952</td>\n",
       "      <td>0.214505</td>\n",
       "      <td>0.021167</td>\n",
       "      <td>0.288775</td>\n",
       "      <td>0.015469</td>\n",
       "      <td>-0.017705</td>\n",
       "      <td>0.316339</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 388 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  pdb_id ligand_resname ligand_chain  ligand_resnum    feat_0    feat_1  \\\n",
       "0      0            FAD            B              1 -0.160192  0.037487   \n",
       "1      1            UNL                           1 -0.140156  0.044201   \n",
       "2    100            UNL                           1 -0.174216  0.054912   \n",
       "3   1000            UNL                           1 -0.210572  0.193983   \n",
       "4   1001            UNL                           1 -0.139574  0.238269   \n",
       "\n",
       "     feat_2    feat_3    feat_4    feat_5  ...  feat_374  feat_375  feat_376  \\\n",
       "0  0.343853  0.107562 -0.045167 -0.109482  ...  0.015290  0.039096  0.030261   \n",
       "1  0.377216  0.274628 -0.066483  0.099652  ...  0.044303 -0.060594  0.118736   \n",
       "2  0.565381  0.199195  0.056334 -0.095419  ...  0.074319 -0.054754  0.080264   \n",
       "3  0.098806 -0.067299  0.027583 -0.232041  ...  0.047724  0.078645 -0.045543   \n",
       "4  0.317292  0.029820  0.067032  0.024362  ...  0.069117  0.075436  0.151512   \n",
       "\n",
       "   feat_377  feat_378  feat_379  feat_380  feat_381  feat_382  feat_383  \n",
       "0  0.059242  0.183268 -0.042948  0.263075  0.095507 -0.121052  0.072660  \n",
       "1 -0.085967  0.095112 -0.050972  0.074142 -0.077221  0.015196  0.454500  \n",
       "2 -0.049534  0.192698 -0.046946  0.171882  0.023477 -0.068335  0.349761  \n",
       "3  0.011250  0.219708  0.067847  0.251348  0.196277 -0.032712  0.107715  \n",
       "4 -0.037952  0.214505  0.021167  0.288775  0.015469 -0.017705  0.316339  \n",
       "\n",
       "[5 rows x 388 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRIPLET_EMBEDDINGS_CSV = BASE_DIR / \"binding_embeddings_triplet.csv\"\n",
    "\n",
    "\n",
    "def compute_triplet_embeddings(\n",
    "    pdb_dir: Path,\n",
    "    binding_groups: dict,\n",
    "    max_groups: int | None = 50,\n",
    "    protein_chains=None,\n",
    "):\n",
    "    keys = list(binding_groups.keys())\n",
    "    if max_groups is not None:\n",
    "        keys = keys[:max_groups]\n",
    "\n",
    "    protein_data_list = []\n",
    "    ligand_data_list = []\n",
    "    inter_data_list = []\n",
    "    meta_list = []\n",
    "\n",
    "    for key in keys:\n",
    "        group_rows = binding_groups[key]\n",
    "        pdb_id, lig_resname, lig_chain, lig_resnum = key\n",
    "        pdb_path = pdb_dir / f\"{pdb_id}.pdb\"\n",
    "\n",
    "        protein_data = build_pyg_data_for_group(pdb_dir, key, group_rows, protein_chains)\n",
    "        if protein_data is None:\n",
    "            continue\n",
    "\n",
    "        ligand_data = build_ligand_graph_from_pdb(pdb_path, lig_resname, lig_chain, lig_resnum)\n",
    "        if ligand_data is None:\n",
    "            continue\n",
    "\n",
    "        inter_data = build_interaction_graph(protein_data, ligand_data)\n",
    "\n",
    "        protein_data_list.append(protein_data)\n",
    "        ligand_data_list.append(ligand_data)\n",
    "        inter_data_list.append(inter_data)\n",
    "        meta_list.append(key)\n",
    "\n",
    "    if not protein_data_list:\n",
    "        print(\"没有成功构建的样本。\")\n",
    "        return None\n",
    "\n",
    "    # 1) 蛋白图编码（先通过 featuriser，再走完整 GCPNet encoder）\n",
    "    protein_batch = to_batch_for_featuriser(protein_data_list)\n",
    "    h_protein = encode_protein_graph(protein_batch)  # [B, Dp]\n",
    "\n",
    "    # 2) 配体图编码\n",
    "    h_ligand = encode_ligand_graph(ligand_data_list)  # [B, Dl]\n",
    "\n",
    "    # 3) 相互作用图编码\n",
    "    h_inter = encode_interaction_graph(inter_data_list)  # [B, Di]\n",
    "\n",
    "    # 拼接三者\n",
    "    H_full = torch.cat([h_protein, h_ligand, h_inter], dim=1).detach().cpu().numpy()\n",
    "\n",
    "    # 构建 DataFrame\n",
    "    records = []\n",
    "    for (pdb_id, lig_resname, lig_chain, lig_resnum) in meta_list:\n",
    "        records.append({\n",
    "            \"pdb_id\": pdb_id,\n",
    "            \"ligand_resname\": lig_resname,\n",
    "            \"ligand_chain\": lig_chain,\n",
    "            \"ligand_resnum\": lig_resnum,\n",
    "        })\n",
    "\n",
    "    df_meta = pd.DataFrame(records)\n",
    "    feat_cols = [f\"feat_{i}\" for i in range(H_full.shape[1])]\n",
    "    df_feat = pd.DataFrame(H_full, columns=feat_cols)\n",
    "    df_out = pd.concat([df_meta, df_feat], axis=1)\n",
    "    df_out.to_csv(TRIPLET_EMBEDDINGS_CSV, index=False)\n",
    "    print(f\"已保存 {len(df_out)} 条三重 embedding 到 {TRIPLET_EMBEDDINGS_CSV}\")\n",
    "\n",
    "    return df_out\n",
    "\n",
    "\n",
    "# 示例运行：先对前 50 个样本构建三图并编码\n",
    "# （注意：这比之前的单图版本更重一点）\n",
    "df_triplet = compute_triplet_embeddings(PDB_DIR, binding_groups, max_groups=50)\n",
    "df_triplet.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
